---
title: 北大AI-杨强
date: 2018-10-02 00:00:00
categories:
- Others
---
#### 传统人工智能方法
##### 符号空间搜索：
穷举法？可以得到所有问题的解
##### 登山算法：
从当前的节点开始，和周围的邻居节点的值进行比较。 如果当前节点是最大的，那么返回当前节点，作为最大值(既山峰最高点)；反之就用最高的邻居节点来，替换当前节点，从而实现向山峰的高处攀爬的目的。如此循环直到达到最高点。
* 缺点：
1. 陷入局部最小；
2. 在山脊震荡，
3. 在平顶失去方向。

##### 博弈树：
##### 逻辑知识表达：
##### 基于概率
##### 机器学习：
##### 自然语言处理
##### 智能规划
#### 最近突破的方法
##### 卷积神经网络
![CNN](https://upload-images.jianshu.io/upload_images/7955445-d132de1eff55ac9b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
##### 深度神经网络
![image.png](https://upload-images.jianshu.io/upload_images/7955445-9514f3dd28d32793.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
##### 深度强化学习
![DDDPMIND](https://upload-images.jianshu.io/upload_images/7955445-b737063d47382756.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
#### 人工智能的方向
- 理解人的意识？
- 深度生成模型：把两图合一
![image.png](https://upload-images.jianshu.io/upload_images/7955445-ba39d4289cf0e246.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
- 基于图像的问答：
#### 单例学习
bayesian program learning（单个例学习），这是从一个例子就能学会，我们知道深度学习是有千万个例子的。实际上它用了我们过去没有涉及到的概念，就叫做**结构**，如果我们了解了一个问题的结构，那么这个结构的一个具体形式只用一个例子就可以学会了。其他的部分，需要很多例子的那一部分可能是参数、统计，这一部分我们实际上可以通过迁移学习来学习。也就是说这个圆就圆满了，就是一个闭环了。看到这么多人工智能的，有失败的时候，有成功的时候，我们到现在能总结出什么经验呢？我觉得现在的人工智能的成功离不开高质量的大数据，但是并不是未来人工智能的成功一定需要大数据。那么我们下面要问是不是在未来有小数据也可以让人工智能成功？大数据开疆拓土、更多的应用和更多的计算能力确实来自于工业。人才培养、小数据研究则依靠学界。这两者结合是我们今后发展的一个方向。
#### 机器学习
#### CNN、RNN、DNN
卷积神经网络、循环神经网络、深度神经网络
- 感知机：包含输入层、输出层和隐含层，即输入的特征向量通过隐含层到达输出层；
- 多层感知机
- DNN：结构上类似于多层感知机
- CNN：由于DNN的隐含层节点过多，CNN利用卷积核做池化。如对一幅图像用100个卷积核，每个卷积核处理后可以得到不同特征的响应；
- RNN：考虑时间序列上的变化，时间上梯度小时的问题，发展长短时记忆单元LSTM，防止梯度消失。
#### Machine Translation
**建立一个中间语言，把所有语言都翻译成中间语言，再转译**  
- Visual Question Answering
