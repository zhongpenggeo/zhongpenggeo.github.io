---
title: 自定义复杂训练 
date: 2020-06-08 16:25:07
categories:
- DeepLearning
---
#### 1. 如何计算loss

```python
# 定义用mean或者其他函数计算loss
loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)

# 获得所有的loss并代入计算函数中
def loss(model, x, y):
  y_ = model(x)

  return loss_object(y_true=y, y_pred=y_)


l = loss(model, features, labels)
print("Loss test: {}".format(l))

# 使用 tf.GradientTape 的前后关系来计算梯度以优化你的模型:
def grad(model, inputs, targets):
  with tf.GradientTape() as tape:
    loss_value = loss(model, inputs, targets)
  return loss_value, tape.gradient(loss_value, model.trainable_variables)

# 使用优化器（如何到达最低点）
optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)
# 用它来计算单个优化步骤：
loss_value, grads = grad(model, features, labels)

print("Step: {}, Initial Loss: {}".format(optimizer.iterations.numpy(),
                                          loss_value.numpy()))
# output：Step: 0, Initial Loss: 2.1644210815429688

optimizer.apply_gradients(zip(grads, model.trainable_variables))
print("Step: {},         Loss: {}".format(optimizer.iterations.numpy(),
                                          loss(model, features, labels).numpy()))
# output： Step: 1,         Loss: 1.8952136039733887

# 循环训练
## Note: 使用相同的模型变量重新运行此单元

# 保留结果用于绘制
train_loss_results = []
train_accuracy_results = []

num_epochs = 201

for epoch in range(num_epochs):
  epoch_loss_avg = tf.keras.metrics.Mean()
  epoch_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()

  # Training loop - using batches of 32
  for x, y in train_dataset:
    # 优化模型
    loss_value, grads = grad(model, x, y)
    optimizer.apply_gradients(zip(grads, model.trainable_variables))

    # 追踪进度
    epoch_loss_avg(loss_value)  # 添加当前的 batch loss
    # 比较预测标签与真实标签
    epoch_accuracy(y, model(x))

  # 循环结束
  train_loss_results.append(epoch_loss_avg.result())
  train_accuracy_results.append(epoch_accuracy.result())

  if epoch % 50 == 0:
    print("Epoch {:03d}: Loss: {:.3f}, Accuracy: {:.3%}".format(epoch,                                                                epoch_loss_avg.result(),                                                               epoch_accuracy.result()))


```

#### 2. 查看损失函数

```python
fig, axes = plt.subplots(2, sharex=True, figsize=(12, 8))
fig.suptitle('Training Metrics')

axes[0].set_ylabel("Loss", fontsize=14)
axes[0].plot(train_loss_results)

axes[1].set_ylabel("Accuracy", fontsize=14)
axes[1].set_xlabel("Epoch", fontsize=14)
axes[1].plot(train_accuracy_results)
plt.show()
```

#### 3. 评估效果

根据测试数据集评估模型

与训练阶段不同，模型仅评估测试数据的一个[周期](https://developers.google.com/machine-learning/glossary/#epoch)。在以下代码单元格中，我们会遍历测试集中的每个样本，然后将模型的预测结果与实际标签进行比较。这是为了衡量模型在整个测试集中的准确率。

```python
test_accuracy = tf.keras.metrics.Accuracy()

for (x, y) in test_dataset:
  logits = model(x)
  prediction = tf.argmax(logits, axis=1, output_type=tf.int32)
  test_accuracy(prediction, y)

print("Test set accuracy: {:.3%}".format(test_accuracy.result()))
```

#### 4. 预测



参考：[https://www.tensorflow.org/tutorials/customization/custom_training_walkthrough#%E5%AE%9A%E4%B9%89%E6%8D%9F%E5%A4%B1%E5%92%8C%E6%A2%AF%E5%BA%A6%E5%87%BD%E6%95%B0](https://www.tensorflow.org/tutorials/customization/custom_training_walkthrough#定义损失和梯度函数)